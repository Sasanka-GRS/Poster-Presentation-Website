<!DOCTYPE html>
<html>
    <head>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
        <link rel="stylesheet" href="sp-project.css">
        <title>Team-25</title>
    </head>
    <body>
      <nav class="navbar navbar-expand-lg navbar-light" style="background-color: #e3f2fd;">
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarTogglerDemo03" aria-controls="navbarTogglerDemo03" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          <img src="home2.png" alt="" width="40" height="40">
        </a>
      
        <div class="collapse navbar-collapse" id="navbarTogglerDemo03">
          <ul class="navbar-nav mr-auto mt-2 mt-lg-0">
            <li class="nav-item active">
              <a class="nav-link" href="slot3.html">Slots<span class="sr-only">(current)</span></a>
            </li>
          </ul>
        </div>
      </nav>
      <a href="https://iiitaphyd-my.sharepoint.com/:i:/g/personal/sasanka_grs_research_iiit_ac_in/EV3XFw5CFahJpu-thvvmjfEB04IH-eC5QLHXcBMc-NJ5QQ?e=oFn9dR">
        <img src="26.jpg" alt="" class="float-right poster">
      </a>
            <div class="col-sm-4 offset-md-1 py-4">
              <div class="row">
                <div class="col-sm-8 col-md-10 py-4">
                  <h3 class="text-white"><u>Multipitch Analysis of Polyphonic Music and Speech Signals Using an Auditory Model</u></h4>
                  
                </div>
              </div>
                <div style="margin-bottom: 20px;">
                  <p class="text-white" >A method is described for estimating the fundamental frequencies of several concurrent sounds in polyphonic music and multiple-speaker speech signals. The method consists of a computational model of the human auditory periphery, followed by a periodicity analysis mechanism where fundamental frequencies are iteratively detected and canceled from the mixture signal. </p>
                
                <p class="text-white" >The auditory model needs to be computed only once, and a computationally efficient strategy is proposed for implementing it. Simulation experiments were made using mixtures of musical sounds and mixed speech utterances. The proposed method outperformed two reference methods in the evaluations and showed a high level of robustness in processing signals where important parts of the audible spectrum were deleted to simulate bandlimited interference. Different system configurations were studied to identify the conditions where pitch analysis using an auditory model is advantageous over conventional time or frequency domain approaches.</p>
                    
                </div>
                
                
                <h3 class="text-white" style="margin-bottom: 20px;"><u>Team Members</u></h4>
                <ul class="list-unstyled" style="margin-bottom: 20px;">
                  <li><a class="text-white">Jahnavi Karnati</a></li>
                  <li><a class="text-white">Akash Vallamsetty</a></li>
                </ul>

                <h4><a href="https://ieeexplore.ieee.org/abstract/document/4358092" target="_blank">Click here</a><span class="text-white"> to access the Research paper</span></h4>
                

              </div>
    </body>    
</html>